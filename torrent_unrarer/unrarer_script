#! /usr/bin/env python
import sys
import os
import shelve
import ConcurrentShelf

'''
@author Vikram Somu
@date 3/29/2015

DEPENDENCIES: 'unrar' unix command line tool

A program for a robot to continually unrar new content and clean 
that content up by deleting it when the rest of the rared content
has been deleted (probably through the Deluge Web UI).

This manager can only be used on a Source Folder (sourcef) where
torrents are moved to said folder AFTER they have completed downloading.
If this condition isn't true, the dirty checking will be fucked up.
'''

'''
Store a memory of archive folders that we have previously
visited. This 'memory' will be a file containing JSON output...
The script will simply read in and write out to this file to both
retrieve and update its memory.

Key -> Value
Folder_Path -> (Folder_State, File_Count)

Folder_State: The state of the folder
- unvisited: any new folder that has not ever been scanned before is 'unvisited'
- visited_clean: folder that has been visited and does not have any extracted content
- visited_dirty: folder has been visited, content was extracted, and is still in the folder

File_Count: Simply the number of files in a folder
'''

class ExtractionManager(object):
    def __init__(self, shelve_file):
        # Concurrent Shelf to represent Folder Memory
        self.cshelf = ConcurrentShelf.ConcurrentShelf(shelve_file)

    # Scan the source folder for unprocessed folders (folders not in memory). 
    # Perform appropriate checking / handling actions
    # on files based on file type and state.

    # In our case, root sourcef wil be: (/var/www/html/dl)
    # We recursively call scan_sourcef on unvisited subdirs
    def scan_sourcef(self, sourcef):
        for file in os.listdir(sourcef):
            fp = sourcef + '/' + file

            # Check to be sure fp points to a directory
            if os.path.isdir(fp):
                # file not in memory, thus unvisited
                if not self.cshelf.get(fp):
                    numfiles_in_fp = self.count_files(fp)
                    # Add it as unvisited with current number of files in directory
                    self.cshelf.set(fp, ('unvisited', numfiles_in_fp))
                    # Handle Unvisited Folder Checking
                    self.handle_unvisited_fp(fp)
                    # Recursively scan this newly found subdir

                else: # File is in memory
                    curstate = self.cshelf.get(fp) #(File_State, File_Count)

                    # Only handle 'visited_dirty' not 'visited_clean' since those are done
                    if curstate == 'visited_dirty':


    # Utility function to check unvisited fp for rar files and extract them

    # If a folder is unvisited, visit it and scan for .rar files
        # We must update memory of fp to 'visited_dirty' before we scan. 
        # Now scan by recursively looking through all sub-folders for any .rar files
    def handle_unvisited_fp(self, fp):
        unrared_lens = []

        for file in os.listdir(fp):
            # Check for file with ending .rar
            if file.endswith(".rar"):
                # Check to make sure we haven't unrared other .rar files that are 
                # the same length  (this case is common with multi-part file archives)
                if len(file) not in unrared_lens:
                    unrared_lens.append(len(file))
                    # If .rar file is found, we will issue the command 'unrar x filename' on it.
                    # BE SURE TO CHANGE STATE IN MEMORY BEFORE STARTING EXTRACTION.
                    # Since we don't want duplicate extraction
                    rarfp = fp + '/' + file
                    self.cshelf.set(fp, ('visited_dirty', 'PROCESSING'))
                    os.system('unrar x {0}'.format(rarfp))
                    filect = self.count_files(fp)
                    self.cshelf.set(fp, ('visited_dirty', filect))
                    dirty = True





        pass

    # Utility function to check dirty fp for change in file count
    def handle_dirty_fp(self, fp):
        pass


        # return unvisited files
        return ret

    # Return number of Hidden/Unhidden Files/Directories in fp
    def count_files(self, fp):
        return len([name for name in os.listdir(fp)])

    def get_parent_dir(self, fp):
        return '/'.join(fp.split('/')[:-1])






em = ExtractionManager('folder_mem.db')
ret = em.scan_sourcef_unvisited('/Users/vikram')
print ret


    # If a folder is visited_clean, we skip over it.

    # If a folder is visited_dirty, we check to see if the # of files
    # currently in the folder is different from the # in memory.
        # If there is a difference, the torrent has been deleted from
        # the deluge Web UI, so we must clean the extracted content
        # by issuing 'rm -rf folderpath'








