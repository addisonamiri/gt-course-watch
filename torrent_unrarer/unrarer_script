#! /usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import os
import shelve
import ConcurrentShelf
import shutil

'''
@author Vikram Somu
@date 3/29/2015

DEPENDENCIES: 'unrar' unix command line tool

A program for a robot to continually unrar new content and clean 
that content up by deleting it when the rest of the rared content
has been deleted (probably through the Deluge Web UI).

This manager can only be used on a Source Folder (sourcef) where
torrents are moved to said folder AFTER they have completed downloading.
If this condition isn't true, the dirty checking will be fucked up.

The fp variable corresponds to file path throughout this program.
'''

'''
Memory Shelf:

Store a memory of archive folders that we have previously
visited. This 'memory' will be a file containing JSON output...
The script will simply read in and write out to this file to both
retrieve and update its memory.

Key -> Value
Folder_Path -> (Folder_State, File_Count)

Folder_State: The state of the folder
- unvisited: any new folder that has not ever been scanned before is 'unvisited'
- visited_clean: folder that has been visited and does not have any extracted content
- visited_dirty: folder has been visited, content was extracted, and is still in the folder
- visited_removed: folder had it's extracted content wiped, and is no longer on the file system.

File_Count: Simply the number of files in a folder
'''

class ExtractionManager(object):
    def __init__(self, shelve_file, save_history):
        # Concurrent Shelf to represent Folder Memory. 
        # This is the Memory shelf
        self.cshelf = ConcurrentShelf.ConcurrentShelf(shelve_file)
        # This param determines whether or not to remove entries from the shelf
        # when said entry's key fp has been removed from the file system
        self.save_history = save_history

    # Scan the source folder for unprocessed folders (folders not in memory). 
    # Perform appropriate checking / handling actions
    # on files based on file type and state.
    # We recursively call scan_sourcefp on unvisited subdirs

    # In our case, root sourcefp wil be: '/var/www/html/dl'
    def scan_sourcefp(self, sourcef):
        # If sourcef is not a dir, break flow of execution
        if not os.path.isdir(sourcef):
            return

        for file in os.listdir(sourcef):
            fp = sourcef + '/' + file
            # print 'all traversed files:', sourcef, file

            # Check to be sure fp points to a directory
            if os.path.isdir(fp):
                # file not in memory, thus unvisited
                if not self.cshelf.get(fp):
                    numfiles_in_fp = self.count_files(fp)
                    # Add it as unvisited with current number of files in directory
                    self.cshelf.set(fp, ('unvisited', numfiles_in_fp))
                    # Visit unvisited Folder Checking
                    self.visit_unvisited_fp(fp)
                else: # File is in the memory shelf      
                    memstate = self.cshelf.get(fp) #(File_State, File_Count)
                    # Check and make sure FP is visited_dirty state!
                    if memstate[0] == 'visited_dirty':
                        self.visit_dirty_fp(fp, memstate)

                # Recursively scan this newly found subdir, whether in memory or not
                # As we need to scan for new unvisited files AS WELL as re-scan
                # old files in the 'visited_dirty' state to re-check state for update
                self.scan_sourcefp(fp)

    # Utility function to check unvisited fp for rar files and extract them
    # and updating state for the fp in the Shelf

    # If a folder is unvisited, visit it and scan for .rar files
        # We must update memory of fp to 'visited_dirty' before we scan. 
        # If no .rar files are found, set state to 'visited_clean'
    def visit_unvisited_fp(self, fp):
        unrared_lens = [] # List of lengths of filenames which we unrared
        dirty = False

        # Walk through the fp dir
        for file in os.listdir(fp):
            # Check for file with ending .rar
            if file.endswith(".rar"):
                # Check to make sure we haven't unrared other .rar files that are 
                # the same length  (this case is common with multi-part file archives)
                if len(file) not in unrared_lens:
                    unrared_lens.append(len(file))
                    # If .rar file is found, we will issue the command 'unrar x filename' on it.
                    # BE SURE TO CHANGE STATE IN MEMORY BEFORE STARTING EXTRACTION.
                    # Since we don't want duplicate extraction
                    rarfp = fp + '/' + file
                    # print 'found rarfp:', rarfp
                    self.cshelf.set(fp, ('visited_dirty', 'PROCESSING'))
                    # Issue shell unrar command on rarfp -> fp
                    os.system('unrar x {rarfile} {dest_dir}'.format(
                            rarfile=rarfp,
                            dest_dir=fp
                        )
                    )
                    # Determine new file count, after unrar
                    filect = self.count_files(fp)
                    self.cshelf.set(fp, ('visited_dirty', filect))
                    dirty = True

        # If clean, set state to 'visited_clean'
        if not dirty:
            filect = self.count_files(fp)
            self.cshelf.set(fp, ('visited_clean', filect))


    # Utility function to check dirty fp for change in file count
    # If the number of files in the directory decreases, we
    # anihilate the directory from the file system and the memory shelf

    # If a folder is visited_dirty, we check to see if the # of files
    # currently in the folder is different from the # in memory.
        # If the number is lower, the torrent has been deleted from
        # the deluge Web UI, so we must clean the extracted content
        # by issuing 'rm -rf folderpath' (we use a python equivalent)
    def visit_dirty_fp(self, fp, memstate):
        oldct = memstate[1]

        if  oldct != 'PROCESSING':
            curct = self.count_files(fp)
            # Content from folder has been deleted....
            # Time to anihilate the folder completely
            if curct < oldct:
                # rm -rf fp from file system
                shutil.rmtree(fp)
                # Remove or keep entry in the shelf depending on 'self.save_history'
                if not self.save_history:
                    self.cshelf.del_entry(fp)
                else:
                    self.cshelf.set(fp, ('visited_removed', 0))


    # Return number of Hidden/Unhidden Files/Directories in fp
    def count_files(self, fp):
        return len([name for name in os.listdir(fp)])

    def get_parent_dir(self, fp):
        return '/'.join(fp.split('/')[:-1])

def main():
    shelf_name = 'folder_mem.db'
    root_sourcefp = sys.argv[1].strip()
    em = ExtractionManager(shelf_name, True)
    em.scan_sourcefp(root_sourcefp)

main()









